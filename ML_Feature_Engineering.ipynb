{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgID3CvNoFV+jPJdpT+sWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalpanaSharma20117/PW_DATA_ANALYTICS/blob/main/ML_Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering- Assignment"
      ],
      "metadata": {
        "id": "Qv4IlnFFA_0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques1. What is a Parameter?"
      ],
      "metadata": {
        "id": "Yvg_o7j0BJpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. A parameter is a special kind of variable used to pass information into functions or methods.When you define a function, parameters are the placeholders in the function definition. When you call the function, you provide arguments (actual values) to those parameters."
      ],
      "metadata": {
        "id": "vEOqRzOcBM3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques2. What is correlation?What does negative correlation mean?\n",
        "\n"
      ],
      "metadata": {
        "id": "dJejWdceBe53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Correlation is a statistical measure that describes the relationship between two variables — specifically, how one variable changes in relation to another.Correlation tells us whether and how strongly two things are related.\n",
        "* There are 3 types of correlation>>\n",
        "1. Positive\n",
        "2. Negative\n",
        "3. Zero/None\n",
        "\n",
        "* Negative correlation means that when one variable increases, the other decreases, and vice versa.  \n",
        "eg.Exercise vs. Weight\n",
        "More exercise → Less weight\n",
        "(As exercise increases, weight tends to decrease.)"
      ],
      "metadata": {
        "id": "UY96VEImBjH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques3. Define Machine Learning. What are the main components in Machine Learning?\n"
      ],
      "metadata": {
        "id": "WNmmCxoSB2cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning is a branch of artificial intelligence(AI) that enables computers to learn from data and make decisions or predictions without being explicitly programmed, it allows systems to automatically improve their performance by learning from experience (data).\n",
        "\n",
        "* Machine Learning = Data + Features + Algorithm → Trained Model → Predictions\n",
        "\n",
        "*Main Components of Machine Learning:\n",
        "1. Data\n",
        "2. Features\n",
        "3. Model\n",
        "4. Algorithm\n",
        "5. Training\n",
        "6. Testing / Evaluation\n",
        "7.  Prediction"
      ],
      "metadata": {
        "id": "_G50NUbSCKcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques4. How does loss value help in determining whether the model is good or not?\n"
      ],
      "metadata": {
        "id": "FJBGFcqeDP7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.The loss value is a numeric measure of how well (or poorly) your machine learning model is performing. It tells you how far off your model's predictions are from the actual target values.\n",
        "\n",
        "High loss value = model is making big mistakes.\n",
        "\n",
        "Low loss value = model is making small mistakes (good performance).\n",
        "\n"
      ],
      "metadata": {
        "id": "gasapm3SDV6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques 5. What are continuous and categorical variables?\n"
      ],
      "metadata": {
        "id": "HYZ6uyrUD4FO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.\n",
        "1. Continuous Variables: These are numerical variables that can take any value within a range.  \n",
        "Characteristics:\n",
        "They are measurable.  \n",
        "Can take infinite values within a range.  \n",
        "Support mathematical operations like averaging, subtraction, etc.\n",
        "Height (e.g., 170.2 cm)\n",
        "Weight (e.g., 65.5 kg)\n"
      ],
      "metadata": {
        "id": "sOTw_naiD9Ie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques6. How do we handle categorical variables in Machine Learning? What are the common techniques?"
      ],
      "metadata": {
        "id": "0LMP4HwqEtYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Machine Learning models cannot understand text or labels directly — they need numeric values. So, categorical variables must be converted into numbers before training the model.\n",
        "\n",
        "* Common Techniques to Handle Categorical Variables:\n",
        "\n",
        "1. Label Encoding:\n",
        "Converts each category into a unique number.\n",
        "Suitable for ordinal data (when categories have a natural order).\n",
        "Education Level  \n",
        "High School → 0    \n",
        "Bachelor     → 1    \n",
        "Master       → 2  \n",
        "Use with caution on nominal data — model may assume order where none exists.\n",
        "\n",
        "2. One-Hot Encoding:\n",
        "Creates a new binary column for each category.\n",
        "Used for nominal data (no order).\n",
        "Color: Red, Green, Blue\n",
        "\n",
        "Red    → [1, 0, 0]    \n",
        "Green  → [0, 1, 0]    \n",
        "Blue   → [0, 0, 1]  \n",
        "\n",
        "3. Ordinal Encoding:\n",
        "Similar to label encoding but used intentionally for ordered categories.  \n",
        "eg. Size: Small, Medium, Large  \n",
        "Small  → 1  \n",
        "Medium → 2  \n",
        "Large  → 3\n",
        "\n",
        "4. Binary Encoding:\n",
        "Combines the advantages of label and one-hot encoding.\n",
        "\n",
        "5. Target Encoding (Mean Encoding):\n",
        "Replace category with the mean of the target for that category.  \n",
        "Useful in certain models like tree-based models.  \n",
        "\n"
      ],
      "metadata": {
        "id": "tFfHjCtREznY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques7. What do you mean by training and testing a dataset?\n"
      ],
      "metadata": {
        "id": "yRRyuJo1GiCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In machine learning, the dataset is usually split into two main parts: training and testing datasets.These serve different purposes in building and evaluating your model.  \n",
        "1. Training Dataset:\n",
        "This is the portion of the data used to train (teach) the model.\n",
        "The model learns patterns and relationships between inputs (features) and outputs (labels).\n",
        "Example:\n",
        "If we're building a model to predict house prices:\n",
        "* training data will contain house features (like size, location etc) and actual prices  \n",
        "\n",
        "2. Testing Dataset:\n",
        "This data is not shown to the model during training.  \n",
        "Used to evaluate how well the model performs on unseen data.  \n",
        "Helps check the model accuracy, generalization , nad real-world performance.  \n",
        "Example:  \n",
        "Once the model is trained, you test it with new house features it hasn't seen before and compare the predicted price with the actual price.\n",
        "\n",
        "We split our data>> To avoid overfitting — where the model performs well on training data but fails on new data like 80% training, 20% testing\n",
        "(Other common ratios: 70-30, 75-25)"
      ],
      "metadata": {
        "id": "ap_DASjOGm8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques8. What is sklearn.preprocessing?\n"
      ],
      "metadata": {
        "id": "GILVmvvVJ_Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. sklearn.preprocessing is a module in Scikit-learn (a popular Python machine learning library) that provides tools to prepare and transform data before training a machine learning model.\n",
        "Preprocessing is important coz most of the machine learning models don't work well with raw data and require numerical, scaled aand clean inputs.\n",
        "So, preprocessing helps make your data model-ready.\n",
        "* Key Tools in sklearn.preprocessing:\n",
        "1. StandardScaler :Scales features to have mean = 0 and std = 1 (Z-score normalization)\n",
        "2. MinMaxScaler: Scales data to a specific range, usually [0, 1]\n",
        "3. LabelEncoder: Converts labels (target) into numeric form\n",
        "4. OneHotEncoder: Converts categorical features into binary format\n",
        "5. OrdinalEncoder: Converts categories to ordered integers\n",
        "6. Normalizer: Scales individual samples to unit norm.\n",
        "7. FunctionTransformer: Lets you apply custom functions to data"
      ],
      "metadata": {
        "id": "5OayR0otKBh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques9. What is a Test set?"
      ],
      "metadata": {
        "id": "jZjfikl7PM1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. A test set is a portion of the dataset that is used to evaluate the performance of a trained machine learning model on unseen data.\n",
        "After you train your model on one part of the data (the training set),\n",
        "\n",
        "You test how well it performs using the test set.It shows the true performance of your model.\n",
        "\n"
      ],
      "metadata": {
        "id": "GEoexLCTPP8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques10.How do we split data for model fitting (training and testing) in Python?How do you approach a Machine Learning problem?\n",
        "  "
      ],
      "metadata": {
        "id": "CdyWh39YPsvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. To split data into training and testing sets, you can use the train_test_split() function from Scikit-learn (sklearn.model_selection)."
      ],
      "metadata": {
        "id": "VGyx9JJYP0Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data (X: features, y: target/output)\n",
        "x = [[1], [2], [3],[4],[5],[6],[7],[8]]\n",
        "y = [10,20,30,40,50,60,70,80]\n",
        "\n",
        "# Split data: 80% training, 20% testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size =0.2, random_state =42\n",
        ")\n",
        "\n",
        "print(\"Training Data:\", x_train, y_train)\n",
        "print(\"Testing Data:\", x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXXGOfg_QgpT",
        "outputId": "9343c23e-6950-49d8-8f43-7d706e4352ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: [[1], [8], [3], [5], [4], [7]] [10, 80, 30, 50, 40, 70]\n",
            "Testing Data: [[2], [6]] [20, 60]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X\t>>Input features (independent variables)  \n",
        "y>>Target variable (output/dependent variable)  \n",
        "test_size>> Fraction (or number) of test samples (e.g. 0.2)  \n",
        "train_size>> Optional. Fraction for training (e.g. 0.8)  \n",
        "random_state>>Fixes randomness for reproducibility  \n",
        "shuffle\t>>Whether to shuffle before splitting (default: True)  "
      ],
      "metadata": {
        "id": "NZgxkyUETntb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques11. Why do we have to perform EDA before fitting a model to the data?\n"
      ],
      "metadata": {
        "id": "Va3b6hj2U4bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. EDA is the process of analyzing, visualizing, and understanding your dataset before applying any machine learning model.\n",
        "It helps you make smart decisions about preprocessing, feature selection, and model choice.\n",
        "1. Understand the Data Structure\n",
        "2. Detect Missing or Null Values\n",
        "3. Identify Outliers\n",
        "4. Spot Data Imbalance\n",
        "5. Understand Feature Relationships\n",
        "6. Visualize Trends and Patterns\n"
      ],
      "metadata": {
        "id": "S1UMav7UGxyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques12. What is correlation?\n"
      ],
      "metadata": {
        "id": "v3bDkTTQHW0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "Correlation tells you how much two things move together.\n",
        "\n",
        "If X increases and Y also increases, → positive correlation\n",
        "\n",
        "If X increases and Y decreases, → negative correlation\n",
        "\n",
        "If X changes and Y does not, → no correlation"
      ],
      "metadata": {
        "id": "J1MJ4HdfHiWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques13. What does negative correlation mean?\n"
      ],
      "metadata": {
        "id": "5Nd6BD8IH1Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. A negative correlation means that as one variable increases, the other decreases — they move in opposite directions.\n",
        "More exercise → lower weight\n",
        "This is a negative correlation.\n",
        "\n",
        "*Correlation Coefficient (r):\n",
        "If r = -1 → perfect negative correlation\n",
        "If r = -0.8 → strong negative\n",
        "If r = -0.3 → weak negative\n",
        "If r = 0 → no correlation\n"
      ],
      "metadata": {
        "id": "le_vNU2AH3YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques14. How can you find correlation between variables in Python?\n"
      ],
      "metadata": {
        "id": "J73GeG62INF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. We can find the correlation between variables in Python using libraries like NumPy, Pandas, or SciPy."
      ],
      "metadata": {
        "id": "gYRPWgd5Icsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Hours_Studied\": [1,2,3,4,5],\n",
        "    \"Exam_score\": [50,60,65,70,80]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "correlation = df.corr()\n",
        "\n",
        "print(correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBFE3mFdJA-G",
        "outputId": "c4e86637-8f3e-4b64-a917-c87330e0a3a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Hours_Studied  Exam_score\n",
            "Hours_Studied       1.000000    0.989949\n",
            "Exam_score          0.989949    1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 0.989 means a strong positive correlation between hours studied and exam score"
      ],
      "metadata": {
        "id": "x8kLNyOoJgp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques 15. What is causation? Explain difference between correlation and causation with an example.\n"
      ],
      "metadata": {
        "id": "a-GXoWDnJhju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Causation means that one variable directly affects another — a cause-and-effect relationship.If A causes B, then changing A will directly change B.\n",
        "\n",
        "* Correlation:\n",
        "A relationship or pattern between variables. Can be in any direction.  \n",
        "Ice cream sales ↔ Drowning rates  \n",
        "Ice cream sales increase   \n",
        "Drowning incidents also increase\n",
        "They’re correlated because both    \n",
        "increase in summer — not because one causes the other.   \n",
        "\n",
        "* Causation:\n",
        "A direct cause-effect relationship\n",
        "Always flows from cause to effect.\n",
        "Requires experimental or strong evidence  \n",
        "Smoking → Lung cancer  \n",
        "Smoking increases → Lung cancer cases increase  \n",
        "Studies show that smoking causes damage that leads to cancer.  \n",
        "This is causation.  "
      ],
      "metadata": {
        "id": "oB2r4ymxJnGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques 16. What is an Optimizer? What are different types of optimizers? Explain each with an example."
      ],
      "metadata": {
        "id": "dREbbncZKkR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. A model learns by making predictions, calculating how strong it is(loss), and then the optimizer updates its parameters to reduce that error.\n",
        "* Common IOptimizers\n",
        "1. SGD : Stochastic Gradient Descent, use for Basic optimizer , slow for deep models\n",
        "\n",
        "2. Momemtum: Adds momentum to SGD to avoid local minima, used for Faster convergence\n",
        "\n",
        "3. Adagrad: Adapts learning rate to parameters, works well on sparse data\n",
        "\n",
        "4. RMSProp: Like Adagrad, But handles decaying learning rate\n",
        "\n",
        "5. Adam: Combines Momentum + RMSProp, it's the most popular optimizer\n"
      ],
      "metadata": {
        "id": "R69ULEoMKp_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques17 .What is sklearn.linear_model ?\n",
        ""
      ],
      "metadata": {
        "id": "XZkNaUKRN8gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. sklearn.linear_model is a module in the Scikit-learn library that provides classes and functions to perform linear models for regression and classification tasks.\n",
        "It includes various linear models such as:\n",
        "1. LinearRegression\n",
        "2. LogisticRegression: For binary/multiclass classification\n",
        "3. SGDRegressor, SGDClassifier: Uses Stochastic Gradient Descent for optimization\n",
        "4. Ridge, Lasso, ElasticNet: Regularized linear regression (to prevent overfitting)"
      ],
      "metadata": {
        "id": "wC5EuoIOSKUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques18 .What does model.fit() do? What arguments must be given?\n"
      ],
      "metadata": {
        "id": "Gj1eIUH0TX8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. model.fit(X, y) learns the relationship between the input features X and the target labels y.“Fit the model to the training data so it can make predictions.”\n",
        "\n",
        "* Arguments Required:  \n",
        "X: Feature matrix (input values): 2D array-like of shape (n_samples, n_features)  \n",
        "y: arget labels (output values): 1D array-like of shape (n_samples,)  "
      ],
      "metadata": {
        "id": "iVuKKlMmTf9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Input features\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "# Target values\n",
        "y = np.array([2, 4, 6, 8])\n",
        "\n",
        "# Create a model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "print(model.predict([[5]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBzs9ubuUC1A",
        "outputId": "3e5f98e4-bcff-4d6f-f9a2-293000d8a370"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques19. What does model.predict() do? What arguments must be given?\n"
      ],
      "metadata": {
        "id": "tbPlKP0mURq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The .predict() method in Scikit-learn is used to make predictions on new (unseen) data after the model has been trained using .fit().\n",
        "\n",
        "After learning from training data using model.fit(X, y), the model can be used to predict the output (target variable) for new input data using model.predict(X_new)."
      ],
      "metadata": {
        "id": "S9vkewWzUXQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques20. What are continuous and categorical variables?\n"
      ],
      "metadata": {
        "id": "JM4ujTilUgoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.\n",
        "1. Continuous Variables: Variables that can take any value within a range. These values are usually numerical and measurable.   \n",
        "eg. Height (e.g., 170.5 cm)  \n",
        "Weight (e.g., 62.3 kg)\n",
        "\n",
        "2. Categorical Variables:\n",
        "Variables that represent categories or groups. They may or may not have a natural order.  \n",
        "Types of Categorical Variables:  \n",
        "* Nominal (no order): e.g., gender (male/female), city (Delhi, Mumbai)  \n",
        "* Ordinal (ordered): e.g., education level (high school < bachelor's < master's)  "
      ],
      "metadata": {
        "id": "Fq3S5q8lUkwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques21. What is feature scaling? How does it help in Machine Learning?\n"
      ],
      "metadata": {
        "id": "SH2cC11wVD6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Feature Scaling is a data preprocessing technique used to normalize or standardize the range of independent variables (features) in a dataset.  \n",
        "It ensures that all features contribute equally to the model by bringing them to a comparable scale.  \n",
        "Many machine learning algorithms (especially those based on distance or gradient descent) are sensitive to the scale of the data.\n",
        "If features have very different scales:\n",
        "Some features may dominate others.  \n",
        "Training becomes unstable or slower.  \n",
        "The model may give less accurate predictions.  "
      ],
      "metadata": {
        "id": "SmSorGsCVIqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques22. How do we perform scaling in Python?\n"
      ],
      "metadata": {
        "id": "bvYTDGPnVe3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In Python, the most common way to perform feature scaling is using Scikit-learn’s preprocessing module.  \n",
        "1. Standardization (Z-score normalization)>> This scales data to have mean = 0 and standard deviation = 1.\n",
        "2. Min-Max Scaling (scales data to range [0, 1])\n",
        "3. Robust Scaling (good when your data has outliers)"
      ],
      "metadata": {
        "id": "S4yGmi3KVi-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques23. What is sklearn.preprocessing?\n"
      ],
      "metadata": {
        "id": "65Z93fgIV_Ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. sklearn.preprocessing is a module in Scikit-learn that provides utility functions and classes to prepare and transform data before using it in machine learning models.\n",
        "Machine learning models work best when the input features are well-scaled, normalized, and clean. sklearn.preprocessing helps with:\n",
        "\n",
        "Scaling features\n",
        "\n",
        "Encoding categorical variables\n",
        "\n",
        "Normalizing data\n",
        "\n",
        "Handling missing values (indirectly, via transformers)\n",
        "\n"
      ],
      "metadata": {
        "id": "EQAloT_7WD_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques24. How do we split data for model fitting (training and testing) in Python?\n"
      ],
      "metadata": {
        "id": "DCzRsYeYWUdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. To split data for model fitting (training and testing) in Python, we typically use train_test_split from the sklearn.model_selection module."
      ],
      "metadata": {
        "id": "ULwV_yRuWWrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "AJ2gK78vWjgU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques25. Explain data encoding?\n"
      ],
      "metadata": {
        "id": "zqXiQTyfWp6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Data Encoding is the process of converting categorical (non-numeric) data into a numeric format, which machine learning models can understand and process.\n",
        "Most ML algorithms (like linear regression) cannot work directly with text labels. So, we convert:\"Male\" → 0\n",
        "\"Female\" → 1\n",
        "* Types of Data Encoding:\n",
        "1. Label Encoding\n",
        "2. One-Hot Encoding\n",
        "3. Ordinal Encoding"
      ],
      "metadata": {
        "id": "OEApf_UMWtf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Sy9g48nA-ox"
      },
      "outputs": [],
      "source": []
    }
  ]
}